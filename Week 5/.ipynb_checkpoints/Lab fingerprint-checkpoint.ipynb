{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingerprint Authentication Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab activity, you will obtain a slight intuition on how biometrics systems work in order to validate a person's fingerprint by using Python. Although this may seem far from \"Systems Programming\", it is important to recognise all the work that has to be developed in order to implement this type authentication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Necessary Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this activity, you need to have the following python modules installed in your computer:\n",
    "\n",
    "* numpy\n",
    "* matplotlib\n",
    "* scikit-image\n",
    "* opencv-python\n",
    "* scipy\n",
    "\n",
    "Remember that you can use the command \"!pip install ...\" to install these modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install scikit-image\n",
    "!pip install opencv-python\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, import the installed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Preprocessing an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In moodle there are four images of fingerprints: Two for subject 101 (101_1.tif and 101_2.tif) and two for subject 102 (102_1.tif and 102_2.tif). The first step to create a fingerprint authentication system is to **Register** the users into the database. To do so, we will do the following:\n",
    "* Load and \"binarise\" the image of the fingerprint.\n",
    "* Skeletonise the binarised image.\n",
    "* Extract the corner points of the fingerprint ridges.\n",
    "* Extract the SIFT features of the corners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and binarising the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, save the fingerprint images (in moodle) within the same folder as this notebook. You will use the command \"cv2.imread\" to import the image. This command takes two arguments: the name of the image, and the flag that indicates what type of image to load: 0 for grayscale and 1 for RGB. Usually, biometric images are treated in grayscale. Therefore, we will use the following setting:\n",
    "\n",
    "* img = cv2.imread(**FULL NAME OF THE IMAGE INSIDE QUOTATION MARKS**, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to write the code that will load a fingerprint image into variable \"img\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the image has been imported to Python and has become a numpy array. If you request the variable \"img\", you will notice that the system will output an array instead of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to print the numpy array containing the image \"img\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, you can verify the size of the array by using the \"shape\" command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to see the shape of the variable containg the image \"img\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to see the array as an image, you can use the command :\n",
    "\n",
    "* plt.imshow(img) \n",
    "\n",
    "followed by:\n",
    "\n",
    "* plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to visualise the image contained in the variable \"img\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image has been imported as an array of values that range from 0 (black) to 255 (white). In between, there are multiple shades of gray that may represent noisy pixels. Therefore, a cleaning process called \"binarisation\" is applied to the image in order to get rid of tis noise and to enhance the shape of the fingerprint. To do so, use the \"cv2.threshold\" command:\n",
    "\n",
    "* ret, img_bin = cv2.threshold(img, 127, 255, 0)\n",
    "\n",
    "The argumants of the function indicate that all pixels with a value higher than 127 will become 255, and that pixels with a value smaller than 127 will become 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to write the code that will binarise the fingerprint image creating variable \"img_bin\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print \"img_bin\" to see that the array only includes values 0 and 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to print the numpy array representing the binarised image \"img_bin\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can take a look at \"img_bin\" to see how the binarisation afects the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to visualise the binarised image contained in the variable \"img_bin\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Skeletonisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the image has been binarised, we can apply a filter so that the ridges are thinned and it becomes easier to find the features. To do so, import the \"skeletonize\" module contained in scikit image morphoology package (skimage.morphology):\n",
    "\n",
    "* from skimage.morphology import skeletonize\n",
    "\n",
    "Then we convert the 255 into 1 (since the skeletonisation method works only if the matrix contains ones and zeroes):\n",
    "\n",
    "* img_bin[img_bin == 255] = 1\n",
    "\n",
    "And finally we apply the skeletonisation filter and create a new image called \"img_skeleton\":\n",
    "\n",
    "* img_skeleton = np.asarray(skeletonize(img_bin), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to write the code that will skeletonise the binarised fingerprint image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we can print the numpy array and visualise the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to print the numpy array representing the skeletonised image \"img_skeleton\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to visualise the skeletonised image contained in the variable \"img_skeleton\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findig the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the feature points that describe the fingerprint, we will use two popular methods in image recognition: The first one is called Harris corners (which will transform the image into a Harris corner image with indexes describing how likely a pixel is to be a corner) and the second is Scale Invariant Feature Transform (SIFT), which will extract a vector of descriptor for each of the candidate corners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harris corners\n",
    "\n",
    "To generate the Harris corners image, use the following commands:\n",
    "\n",
    "* img_harris_corners = cv2.cornerHarris(img_skeleton, 3, 3, 0.04)\n",
    "* img_harris_corners_norm = cv2.normalize(img_harris_corners, 0, 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32FC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to write the code that will generate the normalised harris corners image from the skeletonised image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if we inspect the Harris corners image, we will notice that the corners are represented in lighter colours, having a larger value than pixels which are less likely to be true corners of the fingerprint image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to visualise the normalised harris corners image contained in the variable \"img_harris_corners_normalized\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SIFT descriptors\n",
    "\n",
    "To find the descriptors for each corner, first we need to establish a **threshold value**. This means that if a pixel in the Harris corners image has a value larger than the threshold, then it is considered a true corner. We will set this threshold empirically as $125$. Then, we will scan the image for all rows and columns to find and extract the harris corner keypoints. Finally, we will extract the SIFT descriptors of each keypoint by using the $orb.create$ and the $orb.compute$ functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Execute this code to find true harris corners and extract their SIFT descriptors\n",
    "harris_threshold = 125\n",
    "keys_101_1 = []\n",
    "for x in range(0, img_harris_corners_norm.shape[0]):\n",
    "    for y in range(0, img_harris_corners_norm.shape[1]):\n",
    "        if img_harris_corners_norm[x][y] > harris_threshold:\n",
    "            keys_101_1.append(cv2.KeyPoint(y, x, 1))\n",
    "orb = cv2.ORB_create()\n",
    "_, desc_101_1 = orb.compute(img, keys_101_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the variable \"desc_101_1\" to inspect the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to print the descriptors of image 101_1.tif contained in variable \"desc_101_1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"desc_101_1\" should be a numpy array with 1215 rows (each representing one true harris corner point) and 32 columns (each representing a feature). If you are interested to know more about what each of these 32 features represents, you can read the wiki entry for SIFT here:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Scale-invariant_feature_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to verify the shape of variable \"desc_101_1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrolling the Remaining Images\n",
    "\n",
    "Now that the keypoints and descriptors for image 101_1.tif are stored in variables keys_101_1 and desc_101_1 respectively, you can create a function called $enroll$ which you can simply call as many times as you need to extarct the descriptors of any fingerprint image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This cell provides a function that is being called three times anÂ¡d enrolls the remaining 3 images.\n",
    "def enroll(image_name):\n",
    "    '''This function takes the name of the image as input and outputs the keypoints and descriptors.'''\n",
    "    # Step 1: Load the fingerprint image\n",
    "    img = cv2.imread(image_name, 0)\n",
    "    # Step 2: Binarise the loaded image\n",
    "    _, img_bin = cv2.threshold(img, 127, 255, 0)\n",
    "    # Step 3: Skeletonise the binarised image\n",
    "    img_bin[img_bin == 255] = 1\n",
    "    img_skeleton = np.asarray(skeletonize(img_bin), dtype=np.uint8)\n",
    "    # Step 4: Generate the normalised harris corners image from the skeletonised image\n",
    "    img_harris_corners = cv2.cornerHarris(img_skeleton, 3, 3, 0.04)\n",
    "    img_harris_corners_norm = cv2.normalize(img_harris_corners, 0, 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32FC1)\n",
    "    # Step 5: Extract the SIFT features of the true harris corners with a threshold of 125\n",
    "    harris_threshold = 125\n",
    "    keys = []\n",
    "    for x in range(0, img_harris_corners_norm.shape[0]):\n",
    "        for y in range(0, img_harris_corners_norm.shape[1]):\n",
    "            if img_harris_corners_norm[x][y] > harris_threshold:\n",
    "                keys.append(cv2.KeyPoint(y, x, 1))\n",
    "    orb = cv2.ORB_create()\n",
    "    _, desc = orb.compute(img, keys)\n",
    "    return keys, desc\n",
    "\n",
    "# Call the enroll function three times\n",
    "keys_101_2, desc_101_2 = enroll('101_2.tif')\n",
    "keys_102_1, desc_102_1 = enroll('102_1.tif')\n",
    "keys_102_2, desc_102_2 = enroll('102_2.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching Fingerprints\n",
    "\n",
    "Now that we have all keypoints and descriptors for each fingerprint, we will use a **brute force matching** method that will attempt to find the best mapping between a pair of fingerprints. To do so, we will create a function called $enroll-match$ that enrolls and matches two given images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This cell provides a function that enrolls and matches two given fingerprint images.\n",
    "def enroll_match(image_nameA, image_nameB):\n",
    "    '''This function enrolls two fingerprints and matches them using a brute force method.'''\n",
    "    keysA, descA = enroll(image_nameA)\n",
    "    keysB, descB = enroll(image_nameB)\n",
    "    imgA = cv2.imread(image_nameA, 1)\n",
    "    imgB = cv2.imread(image_nameB, 1)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    match = sorted(bf.match(descA, descB), key= lambda match:match.distance)\n",
    "    # Plot keypoints\n",
    "    imgA_keys = cv2.drawKeypoints(imgA, keysA, outImage=None)\n",
    "    imgB_keys = cv2.drawKeypoints(imgB, keysB, outImage=None)\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    axarr[0].imshow(imgA_keys)\n",
    "    axarr[1].imshow(imgB_keys)\n",
    "    plt.show()\n",
    "    # Plot matches\n",
    "    img_match = cv2.drawMatches(imgA, keysA, imgB, keysB, match, flags=2, outImg=None)\n",
    "    plt.imshow(img_match)\n",
    "    plt.show()\n",
    "    return match\n",
    "\n",
    "# Call the function\n",
    "match = enroll_match('101_1.tif', '102_2.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the \"goodness\" of the match\n",
    "\n",
    "As commented before, the key of biometrics is that you can never guarantee an exact match (unless you are comparing the same two images), but rather you are matching two images and declaring if they belong to the same subject or not based on a score threshold. This score is calculated based on the distance between one matched feature and the other. Moreover, the score threshold is set empirically based on previous experiments\n",
    "\n",
    "For this example, we will set the acceptance threshold equal to 73. This means that if the matching obtains a score of 73 or lower, then the two fingerprints are of the same person, and if the value is higher, then the fingerprints don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This cell provides a function that analyses the \"score\" of a match and deduces if the images are the same or not.\n",
    "def score(match):\n",
    "    '''This function takes a math and returns the visualisation of the matching and a decision of the match.'''\n",
    "    score = 0\n",
    "    score_threshold = 73\n",
    "    for ma in match:\n",
    "        score += ma.distance\n",
    "    score = score/len(match)\n",
    "    print('Score is', score)\n",
    "    if score < score_threshold:\n",
    "        print(\"Fingerprint matches.\")\n",
    "    else:\n",
    "        print(\"Fingerprint does not match.\")\n",
    "    return\n",
    "\n",
    "## Run all functions\n",
    "match = enroll_match('101_1.tif', '101_2.tif')\n",
    "score(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**: Create a single function called $matchFingerprint$ which includes $enroll$, $enroll-match$ and $score$. Moreover, allow $harris-threshold$ and $score-threshold$ to be parameters of this function so that they can be changed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use this cell to implement the matchFingerprint function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
